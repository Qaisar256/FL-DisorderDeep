{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCFUTVycIfWz"
      },
      "outputs": [],
      "source": [
        "# Lung Disease Classification using Custom Models and CatBoost\n",
        "\n",
        "#This notebook demonstrates the process of classifying lung diseases using custom deep learning models and the CatBoost classifier. The process involves loading images, feature extraction using Hierarchical GCN (HGCN) and DeepenShuffleNet, and finally classification.\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, import all necessary libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, GlobalAveragePooling2D, Conv2D\n",
        "from tensorflow.keras.applications import ShuffleNetV2\n",
        "from spektral.layers import GraphConv\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, cohen_kappa_score, matthews_corrcoef"
      ],
      "metadata": {
        "id": "IamYlphsImNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def HGCN(input_shape, num_classes):\n",
        "    X_in = Input(shape=input_shape)\n",
        "    graph_conv1 = GraphConv(64, activation='relu')([X_in, X_in])\n",
        "    graph_conv2 = GraphConv(64, activation='relu')([graph_conv1, X_in])\n",
        "    flatten = Flatten()(graph_conv2)\n",
        "    dense = Dense(128, activation='relu')(flatten)\n",
        "    output = Dense(num_classes, activation='softmax')(dense)\n",
        "    model = Model(inputs=X_in, outputs=output)\n",
        "    return model\n",
        "\n",
        "def DeepenShuffleNet(input_shape, num_classes):\n",
        "    base_model = ShuffleNetV2(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "0NxYnAsyI9TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        if img_path.endswith(\".png\"):\n",
        "            img = load_img(img_path, target_size=(128, 128, 3))\n",
        "            img_array = img_to_array(img)\n",
        "            images.append(img_array)\n",
        "            labels.append(folder.split('/')[-1])\n",
        "    return np.array(images), labels\n"
      ],
      "metadata": {
        "id": "ziPsAR6SJFE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(images, model_func, num_classes):\n",
        "    model = model_func(images[0].shape, num_classes)\n",
        "    features = model.predict(images)\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "a1fn4N-qJJjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "    fpr = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
        "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    mcc = matthews_corrcoef(y_true, y_pred)\n",
        "    return {\n",
        "        \"Recall\": recall,\n",
        "        \"False Positive Rate\": fpr,\n",
        "        \"Precision\": precision,\n",
        "        \"F1 Score\": f1,\n",
        "        \"Cohen's Kappa\": kappa,\n",
        "        \"Matthews Correlation Coefficient\": mcc\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ng73leM4JNdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    diseases = ['Healthy', 'COPD', 'Asthma', 'Pneumonia', 'URTI', 'Bronchiectasis', 'Bronchiolitis', 'LRTI']\n",
        "    augmented_path = 'c://sampledata//augmented'\n",
        "\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    for disease in diseases:\n",
        "        folder_path = os.path.join(augmented_path, disease)\n",
        "        images, labels = load_images_from_folder(folder_path)\n",
        "\n",
        "        hgcn_features = feature_extraction(images, HGCN, len(diseases))\n",
        "        deep_shuffle_net_features = feature_extraction(images, DeepenShuffleNet, len(diseases))\n",
        "        combined_features = np.concatenate((hgcn_features, deep_shuffle_net_features), axis=1)\n",
        "\n",
        "        all_features.append(combined_features)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "    all_features = np.vstack(all_features)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(all_features, all_labels, test_size=0.2, random_state=42)\n",
        "    catboost_model = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=3, verbose=False)\n",
        "    catboost_model.fit(X_train, y_train)\n",
        "    y_pred = catboost_model.predict(X_test)\n",
        "    metrics = calculate_metrics(y_test, y_pred)\n",
        "    for metric, value in metrics.items():\n",
        "        print(f'{metric}: {value:.3f}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "4ikLPLS5JNiw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}