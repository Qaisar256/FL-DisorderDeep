{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Federated Learning for Lung Disease Classification Using Custom Models and FedProx\n",
        "\n",
        "This notebook demonstrates setting up a federated learning system using TensorFlow Federated (TFF) to classify lung diseases with a complex architecture involving hierarchical graph convolutional networks (HGCN) and Deepen-ShuffleNet for feature extraction, and CatBoost for classification, utilizing the FedProx algorithm for training across decentralized clients.\n",
        "\n",
        "## Imports and Setup\n",
        "\n",
        "```python\n",
        "!pip install tensorflow-federated\n",
        "!pip install catboost\n",
        "!pip install spektral\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import numpy as np\n",
        "import os\n",
        "from catboost import CatBoostClassifier\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, GlobalAveragePooling2D, Conv2D\n",
        "from spektral.layers import GraphConv\n",
        "\n",
        "tff.backends.native.set_local_execution_context()\n"
      ],
      "metadata": {
        "id": "IamYlphsImNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def HGCN(input_shape, num_classes):\n",
        "    X_in = Input(shape=input_shape)\n",
        "    graph_conv1 = GraphConv(64, activation='relu')([X_in, X_in])\n",
        "    graph_conv2 = GraphConv(64, activation='relu')([graph_conv1, X_in])\n",
        "    flatten = Flatten()(graph_conv2)\n",
        "    dense = Dense(128, activation='relu')(flatten)\n",
        "    output = Dense(num_classes, activation='softmax')(dense)\n",
        "    model = Model(inputs=X_in, outputs=output)\n",
        "    return model\n",
        "\n",
        "def DeepenShuffleNet(input_shape, num_classes):\n",
        "    base_model = ShuffleNetV2(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "0NxYnAsyI9TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_combined_model():\n",
        "    # Assuming these functions return TensorFlow models ready for training\n",
        "    hgcn_model = HGCN((128, 128, 3), 8)  # Placeholder function\n",
        "    deepen_model = DeepenShuffleNet((128, 128, 3), 8)  # Placeholder function\n",
        "\n",
        "    # This is an abstraction. In practice, you'll need to ensure these models can be combined appropriately and their outputs can be concatenated or otherwise combined to feed into CatBoost.\n",
        "    def model_fn():\n",
        "        return tff.learning.from_keras_model(\n",
        "            keras_model=combined_model,  # This would be your actual implementation\n",
        "            input_spec=input_spec,\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "            metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "    return model_fn"
      ],
      "metadata": {
        "id": "MB9PWnctK8LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        if img_path.endswith(\".png\"):\n",
        "            img = load_img(img_path, target_size=(128, 128, 3))\n",
        "            img_array = img_to_array(img)\n",
        "            images.append(img_array)\n",
        "            labels.append(folder.split('/')[-1])\n",
        "    return np.array(images), labels\n"
      ],
      "metadata": {
        "id": "ziPsAR6SJFE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(images, model_func, num_classes):\n",
        "    model = model_func(images[0].shape, num_classes)\n",
        "    features = model.predict(images)\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "a1fn4N-qJJjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_fedprox_optimizer(mu=0.01):\n",
        "    def optimizer_fn():\n",
        "        return tff.learning.optimizers.build_sgdm(learning_rate=0.02, momentum=0.9, proximal_coeff=mu)\n",
        "    return optimizer_fn\n",
        "\n",
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    model_fn=create_combined_model(),\n",
        "    client_optimizer_fn=build_fedprox_optimizer(mu=0.01),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))\n"
      ],
      "metadata": {
        "id": "1A0jkwwhLIIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = iterative_process.initialize()\n",
        "num_rounds = 10\n",
        "for round_num in range(1, num_rounds + 1):\n",
        "    state, metrics = iterative_process.next(state, federated_train_data)  # federated_train_data needs to be prepared\n",
        "    print('Round {:2d}, Metrics: {}'.format(round_num, metrics))\n"
      ],
      "metadata": {
        "id": "Oc_Chf0wLPjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "    fpr = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
        "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    mcc = matthews_corrcoef(y_true, y_pred)\n",
        "    return {\n",
        "        \"Recall\": recall,\n",
        "        \"False Positive Rate\": fpr,\n",
        "        \"Precision\": precision,\n",
        "        \"F1 Score\": f1,\n",
        "        \"Cohen's Kappa\": kappa,\n",
        "        \"Matthews Correlation Coefficient\": mcc\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ng73leM4JNdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate data distribution among clients\n",
        "def client_data_simulation(disease, augmented_path):\n",
        "    folder_path = os.path.join(augmented_path, disease)\n",
        "    images, labels = load_images_from_folder(folder_path)\n",
        "    return images, labels\n",
        "\n",
        "# Example model function for TFF\n",
        "def create_tff_model():\n",
        "    # Input layer for image features\n",
        "    inputs = Input(shape=(128, 128, 3))  # Adjust the input shape based on your actual data\n",
        "\n",
        "    # Let's say each disease contributes one client's model\n",
        "    # Feature extraction can be mocked by simple layers, you would put your actual model architecture here\n",
        "    x = Flatten()(inputs)\n",
        "    outputs = Dense(8, activation='softmax')(x)  # Assuming 8 classes corresponding to the diseases\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return tff.learning.from_keras_model(\n",
        "        model,\n",
        "        input_spec=(tf.TensorSpec(shape=[None, 128, 128, 3], dtype=tf.float32), tf.TensorSpec(shape=[None], dtype=tf.int32)),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "# Define the federated computation\n",
        "def federated_model_fn():\n",
        "    return create_tff_model()\n",
        "\n",
        "# FedProx optimizer\n",
        "def build_fedprox_optimizer(mu=0.01):\n",
        "    def optimizer_fn():\n",
        "        return tff.learning.optimizers.build_sgdm(learning_rate=0.02, momentum=0.9, proximal_coeff=mu)\n",
        "    return optimizer_fn"
      ],
      "metadata": {
        "id": "H-nMcsM4MDvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    diseases = ['Healthy', 'COPD', 'Asthma', 'Pneumonia', 'URTI', 'Bronchiectasis', 'Bronchiolitis', 'LRTI']\n",
        "    augmented_path = 'c://sampledata//augmented'\n",
        "\n",
        "    # Federated data simulation\n",
        "    client_datasets = [client_data_simulation(disease, augmented_path) for disease in diseases]\n",
        "\n",
        "    # Setting up the federated training process\n",
        "    iterative_process = tff.learning.build_federated_averaging_process(\n",
        "        model_fn=federated_model_fn,\n",
        "        client_optimizer_fn=build_fedprox_optimizer(mu=0.01),\n",
        "        server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0)\n",
        "    )\n",
        "\n",
        "    state = iterative_process.initialize()\n",
        "\n",
        "    # Assuming one round of training per disease\n",
        "    for round_num, client_data in enumerate(client_datasets, 1):\n",
        "        state, metrics = iterative_process.next(state, [client_data])\n",
        "        print(f'Round {round_num}, Metrics: {metrics}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "4ikLPLS5JNiw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}